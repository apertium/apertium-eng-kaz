ubuntu@ubuntu-virtual-machine:~/Source/apertium-eng-kaz$ perl  ../apertium-eval-translator/apertium-eval-translator-line.pl -t translatedVersion.txt -r cleanVersion.txt
perl  ../apertium-eval-translator/apertium-eval-translator-line.pl -t translatedVersion.txt -r texts/kazakhstan1.kaz.txt 

Statistics about input files
-------------------------------------------------------
Number of words in reference: 490
Number of words in test: 381
Number of unknown words (marked with a star) in test: 28
Percentage of unknown words: 7.35 %

Results when removing unknown-word marks (stars)
-------------------------------------------------------
Edit distance: 404
Word error rate (WER): 82.45 %
Number of position-independent correct words: 87
Position-independent word error rate (PER): 82.24 %

ubuntu@ubuntu-virtual-machine:~/Source/apertium-eng-kaz$ 

firespeaker> yeah, but linguistics ≠ transducer
<karan__> spectie : i can write my own piece of code for that , we don't need to use a tool for that.
<spectie> well, i cll it morphotactic, because it is the representation before 'phonology' is applied
<spectie> karan, apertium does not do generate-and-rank online
<firespeaker> spectie: what language is your 5.abl example?
<karan__> it's just searching in a text file, one can do hashing and load as a pickle object
<spectie> firespeaker, kazakh i think
<firespeaker> spectie: a phonological representation means the underlying form
<firespeaker> spectie: okay
<firespeaker> I'll try to generalise it though
<spectie> karan, we like efficient code
<spectie> we like O(n)
<spectie> and under
* ergaurav2 has quit (Quit: Leaving)
* ergaurav2 (~ergaurav2@14.139.82.6) has joined #apertium
<karan__> specte. yeah !! that's must for an online system. so we can simply keep unigrams as in morphological dictionary with frequency, and pick the one with higher frequency for now.
* prth (~prth@223.196.216.43) has joined #apertium
<firespeaker> spectie: жақсы келетін еді’ ‘(the) good (ones) would come’.
<firespeaker> where did you get that example?
<firespeaker> , жақсы китап ‘good book’
<firespeaker> :\
<Aida> firespeaker, I tried, thank you!
<firespeaker> Aida: did you get a result?
<Aida> Is it translatedVersion is text after apertium -d. eng-kaz?
<Aida> and cleanVer.txt is just text in English?
<karan__> specite: for this we just need to load the dictionary and then searchin for it will be just O(1), i don't know who efficient it will be for disambiquating
<karan__> i can try for a text
<Aida> firespeaker, yes
<Aida> I got:
<Aida> perl  ../apertium-eval-translator/apertium-eval-translator-line.pl -t first_diag.txt -r kazakhstan1.raw.txt
<Aida> Use of uninitialized value in addition (+) at ../apertium-eval-translator/apertium-eval-translator-line.pl line 77, <REF> line 13.
<Aida> Statistics about input files
<Aida> -------------------------------------------------------
<Aida> Number of words in reference: 490
<Aida> Number of words in test: 381
<Aida> Number of unknown words (marked with a star) in test: 28
<Aida> Percentage of unknown words: 7.35 %
<Aida> Results when removing unknown-word marks (stars)
<Aida> -------------------------------------------------------
<Aida> Edit distance: 404
<Aida> Word error rate (WER): 82.45 %
<Aida> Number of position-independent correct words: 87
<Aida> Position-independent word error rate (PER): 82.24 %
<spectie> firespeaker, i made it up
<spectie> firespeaker, i told you i was going to make stuff up
<spectie> Aida, please use pastebin
<Aida> ok, sorry :)
<firespeaker> spectie: what is it all cop.ger_past ??
<firespeaker> *why
<firespeaker> Aida: 82.24% is really high
<firespeaker> Aida: so your goal will be to get that much lower\
<firespeaker> :)
<Aida> firespeaker, Is it translatedVersion is text after apertium -d. eng-kaz?and cleanVer.txt is just text in English?
<firespeaker> spectie: hrm, is that really what the transducers return ?  :\
<spectie> firespeaker, yes
<firespeaker> Aida: hm, no
<spectie> Aida, you didn't remove all diagnostics
<spectie> Aida, righ?
<spectie> right ?
<firespeaker> Aida: if it's Kazakh→English, then you first translate the text using the apertium -d kaz-eng, and that's translatedVersion
<Aida> which diagnostics?
<spectie> or did i miss something ?
<spectie> Aida, @ # *
<Aida> it is eng-kaz
<firespeaker> Aida: then the clean version is when you take the output of the translation and make it good English
* shahofblah (~admin@59.178.169.160) has joined #apertium
<firespeaker> ah, then it's just the other way aroun d
<Aida> firespeaker, by hand?
<Aida> or adding vocabulary and etc.?
<firespeaker> you clean the text by hand
<firespeaker> so that it's a good translation


=== Workplan ===
{|class="wikitable"
! week
! dates
!style="width: 25%"| goals
! eval
!style="width: 25%"| accomplishments
!style="width: 35%"| notes
|-
!colspan="2" style="text-align: right"|post-application period<br />23 March - 17 April
|
# finish coding challenge with WER ~30%
# total 300 stems in dix
| {{Workeval5|4}}
|
# ---
# ---
|
* Demonstrated ability to add stems to dix and lexc.
* A couple easy lexical selection rules are still not written.
* Needs for transfer rules in eng-kaz.t2x
|-
!colspan="2" style="text-align: right"|community bonding period<br />17 April - 1 June
|
# run first testvoc
# run coverage scripts
# get first frequency lists
# write ≥4 lexical selection rules
# write ≥3 transfer rules
# write ≥4 disambig rules
note: should be in IRC every day
| {{Workeval5|3}}
|
# —
# --
# --
# --
# --
# —
|
* demonstrated ability to work with lexical selection rules
* demonstrated ability to work with transfer rules
* demonstrated ability to work with constraint grammar rules
* got only some experience with coverage scripts


|-
! 1
!style="text-align: right"| 1 - 22 June
|
# total 1500 stems in dix
# clean testvoc for {{tag|postadv}} {{tag|ij}}
# adding transfer rules
# 500-word evaluation, WER ~30%

| {{Workeval5|0}} 
|
|

|-
! 2
!style="text-align: right"| 23 - 29 June
|
# total 2200 stems in dix
# clean testvoc for {{tag|num}} {{tag|post}}
# adding transfer rules

| {{Workeval5|0}}
|
# -
|

|-
! 3 
!style="text-align: right"| 30 - 6 July
|
# total 2900 stems in dix
# clean testvoc for {{tag|cnjcoo}} {{tag|cnjadv}} {{tag|cnjsub}}
# adding transfer rules

| {{Workeval5|2}}
| 
# --
# --
|

|- 
! 4
!style="text-align: right"| 7 - 13 July
|
# total 3600 stems in dix
# clean testvoc for {{tag|adv}}
# adding transfer rules

|{{Workeval5|2}}
| 
# --
# --
|

|- 
! 5 
!style="text-align: right"| 14 - 20 July
|
# total 4200 stems in dix
# clean testvoc for {{tag|prn}} {{tag|det}}
# adding transfer rules
|{{Workeval5|3}}
| 
# --
# --
|
|- 
! 6 
!style="text-align: right"| 21 - 27 July
|
# total 4900 stems in dix
# clean testvoc for {{tag|adj}} {{tag|adj}}{{tag|advl}}
# adding transfer rules
|{{Workeval5|3}}
|
# ---
# ---
|
|- 
! 7 
!style="text-align: right"| 28 - 3 August
|
# total 5600 stems in dix
# adding transfer rules
|{{Workeval5|2}}
|
# ---
# ---
|
|- 
! 8
!style="text-align: right"| 4 - 10 August
|
# total 6200 stems in dix
# clean testvoc for {{tag|n}} {{tag|num}}{{tag|subst}} {{tag|np}} {{tag|adj}}{{tag|subst}}
# adding transfer rules
|{{Workeval5|2}}
| 
# --
# --
|
|- 
! 9
!style="text-align: right"| 11 - 17 August
|
# total 6900 stems in dix
# adding transfer rules
|{{Workeval5|2}}
| 
# --
# --
|
|- 
! 10
!style="text-align: right"| 18 - 22 August
|
# total 7600 stems in dix
# adding transfer rules
|{{Workeval5|3}}
| 
# --
# --
|
|- 

|}




